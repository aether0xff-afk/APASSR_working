from __future__ import annotations

"""Command-line entrypoint to run the built-in pentest demo in one step.

Usage (Linux/macOS/WSL):
    python -m pentesting_rl

Usage (Windows PowerShell):
    python -m pentesting_rl

Optional arguments:
    --steps N  Run N decision-making steps (default: 3)

This wraps :func:`pentesting_rl.demo.run_local_demo`, which starts a local HTTP
FLAG server, runs `nmap` with the demo policy, and prints each transition. The
nmap binary must be available on PATH or specified via the ``NMAP_PATH``
environment variable.
"""

import argparse
import pathlib
import sys
from typing import Dict, List

if __package__ in {None, ""}:
    sys.path.append(str(pathlib.Path(__file__).resolve().parent.parent))

from pentesting_rl.demo import (
    run_local_comparison,
    run_local_demo,
    run_target_base_url,
    run_target_demo,
    summarize_history,
)
from pentesting_rl.run_logging import generate_reports


def _print_dmp_config(label: str | None, cfg) -> None:
    if label:
        print(f"\n[{label} DMP config]")
    else:
        print("\n[DMP config]")
    print(
        "  max_steps={max_steps} beta={beta} lambda_err={lambda_err} lambda_cost={lambda_cost} "
        "target_ip={target_ip} tool={tool}".format(
            max_steps=cfg.max_steps,
            beta=cfg.beta,
            lambda_err=cfg.lambda_err,
            lambda_cost=cfg.lambda_cost,
            target_ip=cfg.target_ip,
            tool=cfg.tool_name,
        )
    )
    print(
        "  prophecy_enabled={prophecy_enabled} imagination_enabled={imagination_enabled} "
        "imagination_rollouts={imagination_rollouts} learning_enabled={learning_enabled}".format(
            prophecy_enabled=cfg.prophecy_enabled,
            imagination_enabled=cfg.imagination_enabled,
            imagination_rollouts=cfg.imagination_rollouts,
            learning_enabled=cfg.learning_enabled,
        )
    )


def _extract_flag_updates(updates_detail: Dict[str, List[str]] | None) -> List[str]:
    if not updates_detail:
        return []
    return [str(flag) for flag in updates_detail.get("Flag", [])]


def main(argv: List[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="Run the built-in nmap pentest demo")
    parser.add_argument("--steps", type=int, default=3, help="Number of DMP steps to run")
    parser.add_argument(
        "--target",
        type=str,
        default="",
        help="Target IP/hostname to scan instead of the local demo server",
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default="",
        help="Target base URL to scan instead of --target (ex: http://127.0.0.1:8080)",
    )
    parser.add_argument(
        "--ports",
        type=str,
        default="80,443,8080",
        help="Comma-separated port list for --target runs (default: 80,443,8080)",
    )
    parser.add_argument(
        "--compare-random",
        action="store_true",
        help="Run a random baseline alongside the learnable policy",
    )
    parser.add_argument(
        "--tool",
        type=str,
        default="nmap",
        help=(
            "Tool adapter for --target runs "
            "(nmap, http-headers, http-fetch, robots-sitemap, html-crawler, "
            "dir-enum, hint-scanner, stateful-http, param-influence, or auto)"
        ),
    )
    parser.add_argument(
        "--report-dir",
        type=str,
        default="",
        help="Directory to write run.json/knowledge.json/graph.json/report.md",
    )
    args = parser.parse_args(argv)

    ports = [int(p.strip()) for p in args.ports.split(",") if p.strip()]
    if not ports:
        raise SystemExit("No ports provided. Use --ports to specify target ports.")

    if args.base_url:
        target_label = args.base_url
    elif args.target:
        target_label = args.target
    else:
        target_label = "local-demo"
    print("[입력 하이퍼 파라미터]")
    print(f"  steps={args.steps}")
    print(f"  target={target_label}")
    print(f"  ports={ports}")
    print(f"  compare_random={args.compare_random}")
    print(f"  tool={args.tool}")

    if args.compare_random:
        if args.target:
            print("Warning: --compare-random uses the local demo servers, ignoring --target.")
        results = run_local_comparison(steps=args.steps)
        random_dmp = results["random"]
        policy_dmp = results["policy"]
        for label, dmp in (("random", random_dmp), ("policy", policy_dmp)):
            _print_dmp_config(label, dmp.config)
        random_summary = summarize_history(random_dmp.state.history)
        policy_summary = summarize_history(policy_dmp.state.history)

        print("[Random baseline summary]")
        print(
            "  steps={steps} flags={flags} avg_reward={avg_reward:.4f} unique_combos={unique_combos}".format(
                **random_summary
            )
        )
        print("[Policy summary]")
        print(
            "  steps={steps} flags={flags} avg_reward={avg_reward:.4f} unique_combos={unique_combos}".format(
                **policy_summary
            )
        )

        for label, dmp in (("random", random_dmp), ("policy", policy_dmp)):
            print(f"\n[{label} run details]")
            for idx, transition in enumerate(dmp.state.history):
                updates = transition.get("s_t", {}).get("updated_kk", {})
                reward = transition.get("a_t", {}).get("reward")
                imagination = transition.get("imagination", {})
                print(f"[step {idx}] command={transition.get('command')}")
                print(f"          updated_kk={updates}")
                print(f"          imagination={imagination}")
                if reward is not None:
                    print(
                        f"          reward={reward:.4f} flag_found={transition.get('flag_found')}"
                    )
                else:
                    print(f"          flag_found={transition.get('flag_found')}")
                policy_snapshot = transition.get("policy_snapshot", {})
                if policy_snapshot:
                    print("          policy_table=")
                    for slot, entries in policy_snapshot.items():
                        weights = ", ".join(
                            f"{name}={weight:.3f}" for name, weight in entries
                        )
                        print(f"            {slot}: {weights}")
                knowledge_snapshot = transition.get("knowledge_snapshot", {})
                if knowledge_snapshot:
                    print("          knowledge_store=")
                    for key, values in knowledge_snapshot.items():
                        print(f"            {key}: {values}")

        exit_code = 0 if policy_summary["flags"] or random_summary["flags"] else 1
        if args.report_dir:
            base_dir = pathlib.Path(args.report_dir)
            generate_reports(
                base_dir / "random", random_dmp.state.history, random_dmp.knowledge.store
            )
            generate_reports(
                base_dir / "policy", policy_dmp.state.history, policy_dmp.knowledge.store
            )
        return exit_code

    if args.base_url:
        dmp = run_target_base_url(args.base_url, steps=args.steps, tool_name=args.tool)
    elif args.target:
        dmp = run_target_demo(args.target, ports, steps=args.steps, tool_name=args.tool)
    else:
        dmp = run_local_demo(steps=args.steps)
    cfg = dmp.config
    _print_dmp_config(None, cfg)
    print(f"총 {len(dmp.state.history)} 스텝 실행")
    print("\n[Policy weights after run]")
    if cfg.tool_name != "auto":
        for slot, entries in dmp.policy.describe(cfg.tool_name).items():
            weights = ", ".join(f"{name}={weight:.3f}" for name, weight in entries)
            print(f"  {slot}: {weights}")
    else:
        for tool_name, policy_table in dmp.policy.describe().items():
            print(f"  [tool={tool_name}]")
            for slot, entries in policy_table.items():
                weights = ", ".join(f"{name}={weight:.3f}" for name, weight in entries)
                print(f"    {slot}: {weights}")

    flags: List[str] = []
    for idx, transition in enumerate(dmp.state.history):
        updates = transition.get("s_t", {}).get("updated_kk", {})
        updates_detail = transition.get("updates_detail", {})
        flags.extend(_extract_flag_updates(updates_detail))
        reward = transition.get("a_t", {}).get("reward")
        imagination = transition.get("imagination", {})
        print(f"[step {idx}] command={transition.get('command')}")
        print(f"          updated_kk={updates}")
        print(f"          imagination={imagination}")
        if reward is not None:
            print(f"          reward={reward:.4f} flag_found={transition.get('flag_found')}")
        else:
            print(f"          flag_found={transition.get('flag_found')}")
        policy_snapshot = transition.get("policy_snapshot", {})
        if policy_snapshot:
            print("          policy_table=")
            for slot, entries in policy_snapshot.items():
                weights = ", ".join(f"{name}={weight:.3f}" for name, weight in entries)
                print(f"            {slot}: {weights}")
        knowledge_snapshot = transition.get("knowledge_snapshot", {})
        if knowledge_snapshot:
            print("          knowledge_store=")
            for key, values in knowledge_snapshot.items():
                print(f"            {key}: {values}")

    if flags:
        print(f"FLAG 발견: {flags}")
        exit_code = 0
    else:
        print("FLAG를 찾지 못했습니다. nmap 설치 여부와 방화벽 설정을 확인하세요.")
        exit_code = 1

    if args.report_dir:
        generate_reports(args.report_dir, dmp.state.history, dmp.knowledge.store)

    return exit_code


if __name__ == "__main__":
    raise SystemExit(main())
