"""Run session orchestration for logging and report output."""
from __future__ import annotations

import time
from typing import Callable, Mapping, Sequence

from pentesting_rl.finding_candidates import FindingContext, extract_candidates
from pentesting_rl.novelty_tokens import ActionDescriptor, tokenize_action, tokenize_discovery
from pentesting_rl.run_logging import RunMetadata, RunWriter, build_report, snippet, should_store_blob, write_report


StepHook = Callable[[dict[str, object]], None]


class RunSession:
    def __init__(
        self,
        run_root: str,
        target: dict[str, object],
        environment: dict[str, object],
        schema_version: str = "0.1.0",
        generator_version: str = "mvp",
    ) -> None:
        self.writer = RunWriter(run_root)
        self.metadata = RunMetadata(
            run_id=self.writer.run_id,
            target=target,
            environment=environment,
            run_dir=self.writer.run_dir,
            started_at=time.time(),
        )
        self.schema_version = schema_version
        self.generator_version = generator_version
        self._step_count = 0

    def attach(self, dmp: object) -> None:
        if hasattr(dmp, "set_step_hook"):
            dmp.set_step_hook(self._on_step)

    def detach(self, dmp: object) -> None:
        if hasattr(dmp, "set_step_hook"):
            dmp.set_step_hook(None)

    def _on_step(self, event: dict[str, object]) -> None:
        step_index = int(event.get("step_index", self._step_count))
        tool_name = str(event.get("tool", ""))
        options = event.get("options") or ("", "", "")
        params = event.get("params") or {}
        command = str(event.get("command", ""))
        output = str(event.get("output", ""))
        exec_error = bool(event.get("exec_error", False))
        parse_error = bool(event.get("parse_error", False))
        reward_breakdown = event.get("reward_breakdown") or {}
        new_values = event.get("new_values") or {}
        updates = event.get("updates") or set()

        stdout_ref = None
        errors: list[dict[str, object]] = []
        if output and should_store_blob(output):
            stdout_ref, errors = self.writer.write_text_artifact("stdout", step_index, output)
        if exec_error:
            errors.append(
                {
                    "type": "exec_error",
                    "artifact_kind": "stdout",
                    "path": stdout_ref,
                    "message": "executor reported error",
                    "recover": "continue",
                }
            )
        if parse_error:
            errors.append(
                {
                    "type": "parse_error",
                    "artifact_kind": "stdout",
                    "path": stdout_ref,
                    "message": "parser reported error",
                    "recover": "continue",
                }
            )
        if errors:
            self.metadata.errors.extend(errors)

        stdout_snippet = snippet(output)
        action_desc = ActionDescriptor(
            tool=tool_name,
            what=str(options[0]) if len(options) > 0 else "",
            how=str(options[1]) if len(options) > 1 else "",
            where=str(options[2]) if len(options) > 2 else "",
            command=command,
        )
        action_tokens = tokenize_action(action_desc)
        discovery_tokens = tokenize_discovery(new_values, output)

        runlog_record = {
            "timestamp": time.time(),
            "action": {
                "tool": tool_name,
                "options": options,
                "params": params,
                "command": command,
            },
            "stdout_snippet": stdout_snippet,
            "stdout_ref": stdout_ref,
            "stderr_snippet": "",
            "stderr_ref": None,
            "exec_error": exec_error,
            "parse_error": parse_error,
            "kk_updates": sorted(list(updates)) if isinstance(updates, set) else list(updates),
            "reward_breakdown": reward_breakdown,
            "action_tokens": sorted(action_tokens),
            "discovery_tokens": sorted(discovery_tokens),
            "errors": errors,
        }
        runlog_line = self.writer.append_step(runlog_record)
        self._step_count += 1

        context = FindingContext(
            run_id=self.metadata.run_id,
            target=str(self.metadata.target.get("base_url", "")),
            step_index=step_index,
            runlog_line=runlog_line,
            stdout_ref=stdout_ref,
            stderr_ref=None,
        )
        candidates = extract_candidates(output, new_values, event.get("knowledge"), context)
        if candidates:
            self.metadata.findings.extend(candidates)

    def finalize(self, knowledge_final: Mapping[str, Sequence[str]]) -> None:
        report_payload = build_report(
            self.metadata,
            knowledge_final,
            self._step_count,
            finished_at=time.time(),
            schema_version=self.schema_version,
            generator_version=self.generator_version,
        )
        write_report(self.metadata.run_dir / "report.json", report_payload)

    @property
    def run_id(self) -> str:
        return self.metadata.run_id
